import streamlit as st
from datetime import date, datetime
import pandas as pd
from log import logger
import pytz

# from streamlit_autorefresh import st_autorefresh
import akshare
from akcache import CacheWrapper
from options import analyze_atm_options, find_primary_options
from helpers import during_market_time, minutes_since_market_open, color_text
from streamlit_autorefresh import st_autorefresh
from index_spread import create_spread_chart

ak = CacheWrapper(akshare, cache_time=180)
st.set_page_config("æˆäº¤é‡é¢„æµ‹", "ğŸ“ˆ")


@st.cache_data(ttl=60)
def is_trade_date(date):
    """
    åˆ¤æ–­æ˜¯å¦æ˜¯äº¤æ˜“æ—¥ã€‚

    å‚æ•°:
    date (datetime.date): è¦æ£€æŸ¥çš„æ—¥æœŸã€‚

    è¿”å›:
    bool: å¦‚æœæ˜¯äº¤æ˜“æ—¥ï¼Œåˆ™è¿”å› Trueï¼›å¦åˆ™è¿”å› Falseã€‚
    """
    try:
        stock_calendar = ak.tool_trade_date_hist_sina()
        stock_calendar_dates = pd.to_datetime(stock_calendar["trade_date"]).dt.date
        if date in set(stock_calendar_dates):
            logger.info(f"{date} æ˜¯äº¤æ˜“æ—¥")
            return True
        else:
            logger.info(f"{date} ä¸æ˜¯äº¤æ˜“æ—¥")
            return False
    except Exception as e:
        logger.error(f"æ£€æŸ¥æ—¥æœŸæ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        raise


# åªéœ€è¦æ¯å¤©æ‰§è¡Œä¸€æ¬¡ï¼Œè·å–æˆäº¤é‡åˆ†æ—¶æ¯”ä¾‹
@st.cache_data(ttl=42000)
def get_amount_curve(ndays):
    """
    è·å–æŒ‡å®šå¤©æ•°çš„æˆäº¤é‡æ›²çº¿ã€‚

    å‚æ•°:
    ndays (int): è¦è·å–çš„å¤©æ•°ã€‚

    è¿”å›:
    list: åŒ…å«æ¯15åˆ†é’Ÿæˆäº¤é‡ç™¾åˆ†æ¯”çš„åˆ—è¡¨ã€‚

    å¼‚å¸¸:
    å¦‚æœåœ¨è·å–æˆ–å¤„ç†æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼Œå°†è®°å½•é”™è¯¯å¹¶æŠ›å‡ºå¼‚å¸¸ã€‚

    åŠŸèƒ½æè¿°:
    1. ä» akshare è·å–ä¸Šè¯å’Œæ·±è¯çš„åˆ†é’Ÿæ•°æ®ã€‚
    2. åˆå¹¶æ•°æ®å¹¶è®¡ç®—æ€»æˆäº¤é‡ã€‚
    3. è¿‡æ»¤æ‰å½“å¤©çš„æ•°æ®ï¼Œåªä¿ç•™æŒ‡å®šå¤©æ•°çš„æ•°æ®ã€‚
    4. è®¡ç®—æ¯15åˆ†é’Ÿçš„æˆäº¤é‡å å½“å¤©æ€»æˆäº¤é‡çš„ç™¾åˆ†æ¯”ã€‚
    5. ç”Ÿæˆå¹¶è¿”å›æˆäº¤é‡æ›²çº¿ã€‚

    æ—¥å¿—:
    - è®°å½•è·å–æ•°æ®çš„å¼€å§‹å’ŒæˆåŠŸä¿¡æ¯ã€‚
    - è®°å½•æ•°æ®å¤„ç†å®Œæˆçš„ä¿¡æ¯ã€‚
    - è®°å½•ç™¾åˆ†æ¯”æ•°æ®è®¡ç®—æˆåŠŸçš„ä¿¡æ¯ã€‚
    - è®°å½•ç”Ÿæˆæˆäº¤é‡æ›²çº¿çš„ä¿¡æ¯ã€‚
    - è®°å½•ä»»ä½•å‘ç”Ÿçš„é”™è¯¯ã€‚
    """
    logger.info(f"å¼€å§‹è·å–æˆäº¤é‡æ›²çº¿ï¼Œå¤©æ•°ï¼š{ndays}")
    try:
        stock_zh_a_minute_df_sh = ak.stock_zh_a_minute(
            symbol="sh000001", period="15", adjust="qfq"
        )
        stock_zh_a_minute_df_sz = ak.stock_zh_a_minute(
            symbol="sz399001", period="15", adjust="qfq"
        )
        logger.info("æˆåŠŸè·å–ä¸Šè¯å’Œæ·±è¯åˆ†é’Ÿæ•°æ®")

        df = pd.concat([stock_zh_a_minute_df_sh, stock_zh_a_minute_df_sz], axis=1)
        df2 = df.iloc[:, [0, 5, 11]].copy(deep=True)
        df2.columns = ["day", "amount_sh", "amount_sz"]
        df2["amount_sh"] = pd.to_numeric(df2["amount_sh"])
        df2["amount_sz"] = pd.to_numeric(df2["amount_sz"])
        df2["date"] = pd.to_datetime(
            df2["day"], infer_datetime_format=True
        )  # format='%Y-%m-%d %H:%M:%S'
        df2["totalamount"] = df2.apply(
            lambda x: (x["amount_sh"] + x["amount_sz"]), axis=1
        )
        df2.drop(["day"], axis=1, inplace=True)
        df2 = df2[
            df2["date"] < datetime.combine(date.today(), datetime.min.time())
        ]  # è·å–æœ¬æ—¥ä¹‹å‰15åˆ†é’Ÿæ•°æ®ï¼Œå½“æ—¥ä¸è¦ã€‚
        df2 = df2.tail(ndays * 16)  # å–nå¤©çš„æ•°æ®ï¼Œä¸€å¤©16ä¸ªæ•°æ®ã€‚
        logger.info(f"æ•°æ®å¤„ç†å®Œæˆï¼Œå…±{len(df2)}æ¡è®°å½•")

        df_all = pd.DataFrame()
        for i in range(ndays):
            df_range = df2.iloc[i * 16 : (i + 1) * 16]
            day_amount = df_range.totalamount.sum()
            df_range["pct"] = df_range.apply(
                lambda x: (x["totalamount"] / day_amount), axis=1
            )
            df_range.loc[:, "pct"] = df_range.apply(
                lambda x: (x["totalamount"] / day_amount), axis=1
            )
            df_all = pd.concat([df_all, df_range])
        df_all = df_all.reset_index()
        logger.info(f"æˆåŠŸè®¡ç®—{ndays}å¤©çš„ç™¾åˆ†æ¯”æ•°æ®")

        curve = []
        for j in range(16):
            curve.append(df_all[df_all.index % 16 - j == 0].pct.mean())

        logger.info(f"æˆåŠŸç”Ÿæˆæˆäº¤é‡æ›²çº¿:{curve}")
        return curve
    except Exception as e:
        logger.error(f"è·å–æˆäº¤é‡æ›²çº¿æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        raise


@st.cache_data(ttl=180)
def get_estimate_amount(minutes, vol=None):
    """
    ä¼°ç®—æˆäº¤é‡ã€‚

    å‚æ•°ï¼š
    minutes (int): å·²äº¤æ˜“çš„åˆ†é’Ÿæ•°ã€‚
    vol (int, å¯é€‰): æŒ‡å®šçš„æˆäº¤é‡ã€‚å¦‚æœæœªæä¾›ï¼Œå°†è‡ªåŠ¨è·å–ã€‚

    è¿”å›ï¼š
    int: ä¼°ç®—çš„æˆäº¤é‡ã€‚å¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œè¿”å›0ã€‚

    å¼‚å¸¸ï¼š
    KeyError: å½“è®¡ç®—ç´¯è®¡æ¯”ä¾‹æ—¶å‘ç”Ÿé”®é”™è¯¯ã€‚
    ZeroDivisionError: å½“ä¼°ç®—æˆäº¤é‡æ—¶å‘ç”Ÿé™¤é›¶é”™è¯¯ã€‚

    æ—¥å¿—ï¼š
    - è®°å½•å¼€å§‹ä¼°ç®—æˆäº¤é‡çš„ä¿¡æ¯ã€‚
    - è®°å½•è®¡ç®—å¾—åˆ°çš„ç´¯è®¡æ¯”ä¾‹ã€‚
    - è®°å½•è‡ªåŠ¨è·å–çš„æˆäº¤é‡ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰ã€‚
    - è®°å½•ä¼°ç®—çš„æˆäº¤é‡ã€‚
    - è®°å½•è®¡ç®—ç´¯è®¡æ¯”ä¾‹æ—¶çš„é”®é”™è¯¯è­¦å‘Šã€‚
    - è®°å½•ä¼°ç®—æˆäº¤é‡æ—¶çš„é™¤é›¶é”™è¯¯ã€‚
    """

    logger.info(f"å¼€å§‹ä¼°ç®—æˆäº¤é‡ï¼Œå·²äº¤æ˜“åˆ†é’Ÿæ•°ï¼š{minutes}ï¼ŒæŒ‡å®šæˆäº¤é‡ï¼š{vol}")
    curve = get_amount_curve(3)
    df = pd.DataFrame(curve, columns=["amount"])
    t = minutes // 15
    if t > 15:
        t = 15
    remaining_minutes = minutes % 15

    try:
        a = df[0:t]["amount"].sum() + df.loc[t] * remaining_minutes / 15

        logger.info(f"è®¡ç®—å¾—åˆ°çš„ç´¯è®¡æ¯”ä¾‹ï¼š{a}")
    except KeyError:
        a = df[0:t]["amount"].sum()
        logger.warning(f"è®¡ç®—ç´¯è®¡æ¯”ä¾‹æ—¶å‘ç”ŸKeyErrorï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆï¼š{a}")
        raise

    if not vol:
        total_amount = get_a_amount()
        vol = total_amount[0] + total_amount[1]
        logger.info(f"è‡ªåŠ¨è·å–æˆäº¤é‡ï¼š{vol}")
    try:
        estimated_amount = int(vol / a.iloc[0]) if vol > 0 else 0
        logger.info(f"ä¼°ç®—çš„æˆäº¤é‡ï¼š{estimated_amount}")
        return estimated_amount
    except ZeroDivisionError:
        logger.error("ä¼°ç®—æˆäº¤é‡æ—¶å‘ç”Ÿé™¤é›¶é”™è¯¯")
        return 0


@st.cache_data(ttl=180)
def get_n_day_avg_amount(n):
    """
    è·å–ä¸Šè¯å’Œæ·±è¯æŒ‡æ•°æœ€è¿‘ n ä¸ªäº¤æ˜“æ—¥çš„å¹³å‡æˆäº¤é¢ã€‚

    å‚æ•°:
        n (int): è¦è®¡ç®—çš„äº¤æ˜“æ—¥å¤©æ•°ã€‚

    è¿”å›:
        tuple: åŒ…å«ä¸Šè¯å’Œæ·±è¯æŒ‡æ•°å¹³å‡æˆäº¤é¢çš„å…ƒç»„ï¼Œæ ¼å¼ä¸º (sh_avg_amount, sz_avg_amount)ã€‚
    """
    logger.info(f"å¼€å§‹è·å–æœ€è¿‘ {n} ä¸ªäº¤æ˜“æ—¥çš„å¹³å‡æˆäº¤é¢")
    try:
        stock_zh_a_daily_df_sh = ak.stock_zh_index_daily_em(symbol="sh000001")
        stock_zh_a_daily_df_sz = ak.stock_zh_index_daily_em(symbol="sz399001")
        logger.info("æˆåŠŸè·å–ä¸Šè¯å’Œæ·±è¯æ¯æ—¥æ•°æ®")

        sh_amount = stock_zh_a_daily_df_sh["amount"].iloc[-6:-1].mean()
        sz_amount = stock_zh_a_daily_df_sz["amount"].iloc[-6:-1].mean()

        logger.info(
            f"æœ€è¿‘ {n} ä¸ªäº¤æ˜“æ—¥ä¸Šè¯å¹³å‡æˆäº¤é¢: {sh_amount}, æ·±è¯å¹³å‡æˆäº¤é¢: {sz_amount}"
        )
        return sh_amount + sz_amount
    except Exception as e:
        logger.error(f"è·å–æœ€è¿‘ {n} ä¸ªäº¤æ˜“æ—¥çš„å¹³å‡æˆäº¤é¢æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        return 0, 0


@st.cache_data(ttl=180)
def get_index_price(symbol):
    try:
        index_data = ak.stock_zh_index_spot_em(symbol="æ·±è¯ç³»åˆ—æŒ‡æ•°")
        index_value = index_data[index_data["ä»£ç "] == symbol]["æœ€æ–°ä»·"].values[0]
        return index_value
    except Exception as e:
        logger.error(f"è·å–æŒ‡æ•° {symbol} å½“å‰ä»·æ ¼æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        return None


def get_index_amount(symbol):
    try:
        df_sh = ak.stock_zh_index_spot_em(symbol="ä¸Šè¯ç³»åˆ—æŒ‡æ•°")
        df_sz = ak.stock_zh_index_spot_em(symbol="æ·±è¯ç³»åˆ—æŒ‡æ•°")
        df_csi = ak.stock_zh_index_spot_em(symbol="ä¸­è¯ç³»åˆ—æŒ‡æ•°")
        df = pd.concat([df_sh, df_sz, df_csi], axis=0)

        index_value = df[df["ä»£ç "] == symbol]["æˆäº¤é¢"].values[0]
        return index_value
    except Exception as e:
        logger.error(f"è·å–æŒ‡æ•° {symbol} å½“å‰æˆäº¤é¢æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        return None


# è·å–å½“å‰æˆäº¤é¢
@st.cache_data(ttl=180)
def get_a_amount() -> tuple[float, float]:
    """
    è·å–ä¸Šè¯å’Œæ·±è¯æŒ‡æ•°çš„æˆäº¤é‡ã€‚

    è¯¥å‡½æ•°ä½¿ç”¨ akshare åº“è·å–å½“å‰ä¸Šè¯æŒ‡æ•°å’Œæ·±è¯æŒ‡æ•°çš„æˆäº¤é‡ã€‚
    å¦‚æœå½“å‰æ—¶é—´ä¸åœ¨äº¤æ˜“æ—¶é—´å†…ï¼Œåˆ™å°†å…¨å±€çš„ TTL å˜é‡è®¾ç½®ä¸º 3600 ç§’ã€‚

    è¿”å›:
        tuple: åŒ…å«ä¸Šè¯å’Œæ·±è¯æŒ‡æ•°æˆäº¤é‡çš„å…ƒç»„ï¼Œæ ¼å¼ä¸º (sh_amount, sz_amount)ã€‚

    å¼‚å¸¸:
        KeyError: å¦‚æœåœ¨è·å–çš„æ•°æ®ä¸­æœªæ‰¾åˆ°é¢„æœŸçš„è‚¡ç¥¨ä»£ç ï¼ˆä¸Šè¯ä¸º "000001"ï¼Œæ·±è¯ä¸º "399001"ï¼‰ã€‚
    """

    try:
        logger.info("å¼€å§‹è·å–æŒ‡æ•°æ•°æ®")
        spot_df_sh = ak.stock_zh_index_spot_em(symbol="ä¸Šè¯ç³»åˆ—æŒ‡æ•°")
        spot_df_sz = ak.stock_zh_index_spot_em(symbol="æ·±è¯ç³»åˆ—æŒ‡æ•°")
    except Exception as e:
        logger.error(f"è·å–æŒ‡æ•°æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        return 0, 0

    sh_amount = spot_df_sh[spot_df_sh["ä»£ç "] == "000001"]["æˆäº¤é¢"].values[
        0
    ]  # ä¸Šè¯æˆäº¤é¢
    sz_amount = spot_df_sz[spot_df_sz["ä»£ç "] == "399001"]["æˆäº¤é¢"].values[
        0
    ]  # æ·±è¯æˆäº¤é¢
    logger.info(f"è·å–ä¸Šè¯å’Œæ·±è¯æŒ‡æ•°çš„æˆäº¤é‡: ä¸Šè¯ {sh_amount}, æ·±è¯ {sz_amount}")
    if pd.isna(sh_amount) or pd.isna(sz_amount):
        logger.error("è·å–çš„æˆäº¤é‡æ•°æ®åŒ…å« NaN å€¼")
        return 0, 0

    return sh_amount, sz_amount


@st.cache_data(ttl=180)
def middle_price_change():
    """
    è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„ä¸­ä½æ•°æ¶¨å¹…ã€‚

    è¯¥å‡½æ•°è·å–Aè‚¡çš„å®æ—¶äº¤æ˜“æ•°æ®ï¼Œå¹¶è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„ä¸­é—´æ¶¨å¹…ï¼ˆå³æŒ‰æ¶¨å¹…æ’åºåä½äºä¸­é—´çš„è‚¡ç¥¨æ¶¨å¹…ï¼‰ã€‚

    è¿”å›:
        float: ä¸­é—´è‚¡ç¥¨æ¶¨å¹…ã€‚å¦‚æœæ•°æ®ä¸ºç©ºï¼Œåˆ™è¿”å›0ã€‚
    """
    df = ak.stock_zh_a_spot_em()
    if df.empty:
        logger.info("å®æ—¶è¡Œæƒ…æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—ä¸­é—´æ¶¨å¹…")
        return 0

    # æŒ‰æ¶¨å¹…æ’åº
    df_sorted = df.sort_values("æ¶¨è·Œå¹…")

    # è®¡ç®—ä¸­é—´ä½ç½®
    middle_index = len(df_sorted) // 2

    # è·å–ä¸­é—´æ¶¨å¹…
    middle_price_change = df_sorted.iloc[middle_index]["æ¶¨è·Œå¹…"]
    logger.info(f"ä¸­é—´è‚¡ç¥¨æ¶¨å¹…ä¸º: {middle_price_change}")

    return middle_price_change


@st.cache_data(ttl=180)
def count_limit_up_stocks():
    """
    è®¡ç®—æ¶¨åœæ¿è‚¡ç¥¨çš„æ•°é‡ã€‚

    è¯¥å‡½æ•°è·å–Aè‚¡çš„å®æ—¶äº¤æ˜“æ•°æ®ï¼Œå¹¶è®¡ç®—æ¶¨åœæ¿ï¼ˆæ¶¨å¹…è¾¾åˆ°10%æˆ–ä»¥ä¸Šï¼‰çš„è‚¡ç¥¨æ•°é‡ã€‚

    è¿”å›:
        int: æ¶¨åœæ¿è‚¡ç¥¨çš„æ•°é‡ã€‚å¦‚æœæ•°æ®ä¸ºç©ºï¼Œåˆ™è¿”å›0ã€‚
    """
    df = ak.stock_zh_a_spot_em()
    if df.empty:
        logger.info("å®æ—¶è¡Œæƒ…æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—æ¶¨åœæ¿æ•°é‡")
        return 0

    # è®¡ç®—æ¶¨åœæ¿è‚¡ç¥¨çš„æ•°é‡ï¼Œ30 å¼€å¤´å’Œ 68 å¼€å¤´çš„æ˜¯ 20% æ¶¨åœï¼Œå…¶ä»–æ˜¯ 10% æ¶¨åœ
    df["æ¶¨åœæ¿"] = df.apply(
        lambda row: (
            row["æ¶¨è·Œå¹…"] >= 19.9
            if row["ä»£ç "].startswith(("30", "68"))
            else row["æ¶¨è·Œå¹…"] >= 9.9
        ),
        axis=1,
    )
    limit_up_stocks = df[df["æ¶¨åœæ¿"] & ~df["ä»£ç "].str.startswith("8")].shape[0]
    logger.info(f"æ¶¨åœæ¿è‚¡ç¥¨æ•°é‡: {limit_up_stocks}")

    return limit_up_stocks


@st.cache_data(ttl=180)
def count_limit_down_stocks():
    """
    è®¡ç®—è·Œåœæ¿è‚¡ç¥¨çš„æ•°é‡ã€‚

    è¯¥å‡½æ•°è·å–Aè‚¡çš„å®æ—¶äº¤æ˜“æ•°æ®ï¼Œå¹¶è®¡ç®—è·Œåœæ¿ï¼ˆè·Œå¹…è¾¾åˆ°10%æˆ–ä»¥ä¸Šï¼‰çš„è‚¡ç¥¨æ•°é‡ã€‚

    è¿”å›:
        int: è·Œåœæ¿è‚¡ç¥¨çš„æ•°é‡ã€‚å¦‚æœæ•°æ®ä¸ºç©ºï¼Œåˆ™è¿”å›0ã€‚
    """
    df = ak.stock_zh_a_spot_em()
    if df.empty:
        logger.info("å®æ—¶è¡Œæƒ…æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—è·Œåœæ¿æ•°é‡")
        return 0

    # è®¡ç®—è·Œåœæ¿è‚¡ç¥¨çš„æ•°é‡ï¼Œ30 å¼€å¤´å’Œ 68 å¼€å¤´çš„æ˜¯ 20% è·Œåœï¼Œå…¶ä»–æ˜¯ 10% è·Œåœ
    df["è·Œåœæ¿"] = df.apply(
        lambda row: (
            row["æ¶¨è·Œå¹…"] <= -19.9
            if row["ä»£ç "].startswith(("30", "68"))
            else row["æ¶¨è·Œå¹…"] <= -9.9
        ),
        axis=1,
    )
    limit_down_stocks = df[df["è·Œåœæ¿"] & ~df["ä»£ç "].str.startswith("8")].shape[0]
    logger.info(f"è·Œåœæ¿è‚¡ç¥¨æ•°é‡: {limit_down_stocks}")

    return limit_down_stocks


@st.cache_data(ttl=180)
def stock_up_down_ratio():
    """
    è®¡ç®—è‚¡ç¥¨çš„æ¶¨è·Œæ¯”ã€‚

    è¯¥å‡½æ•°è·å–Aè‚¡çš„å®æ—¶äº¤æ˜“æ•°æ®ï¼Œå¹¶è®¡ç®—ä¸Šæ¶¨è‚¡ç¥¨æ•°é‡ä¸ä¸‹è·Œè‚¡ç¥¨æ•°é‡çš„æ¯”å€¼ã€‚

    è¿”å›:
        float: è‚¡ç¥¨çš„æ¶¨è·Œæ¯”ã€‚å¦‚æœæ•°æ®ä¸ºç©ºï¼Œåˆ™è¿”å›0ã€‚
    """
    df = ak.stock_zh_a_spot_em()
    if df.empty:
        logger.info("å®æ—¶è¡Œæƒ…æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—æ¶¨è·Œæ¯”")
        return 0

    # è®¡ç®—è‚¡ç¥¨æ€»æ•°
    num_stocks = len(df)

    # è®¡ç®—ä¸Šæ¶¨å’Œä¸‹è·Œè‚¡ç¥¨çš„æ•°é‡
    up_stocks = df[df["æ¶¨è·Œå¹…"] >= 0].shape[0]
    down_stocks = df[df["æ¶¨è·Œå¹…"] < 0].shape[0]
    logger.info(f"ä¸Šæ¶¨è‚¡ç¥¨æ•°é‡: {up_stocks}, ä¸‹è·Œè‚¡ç¥¨æ•°é‡: {down_stocks}")
    if down_stocks == 0:
        logger.info("æ²¡æœ‰ä¸‹è·Œçš„è‚¡ç¥¨ï¼Œæ¶¨è·Œæ¯”ä¸ºæ— ç©·å¤§")
        return float("inf")

    up_down_ratio = (up_stocks / num_stocks) * 100
    logger.info(f"è‚¡ç¥¨ä¸Šæ¶¨ç™¾åˆ†æ¯”ä¸º: {up_down_ratio}")

    return up_down_ratio


@st.cache_data(ttl=180)
def top_n_stock_avg_price_change(n):
    """
    è®¡ç®—å‰ n% æˆäº¤é‡‘é¢çš„è‚¡ç¥¨çš„å¹³å‡æ¶¨å¹…ã€‚

    è¯¥å‡½æ•°è·å–Aè‚¡çš„å®æ—¶äº¤æ˜“æ•°æ®ï¼Œå°†è‚¡ç¥¨æŒ‰æˆäº¤é‡‘é¢é™åºæ’åºï¼Œå¹¶è®¡ç®—æ€»æˆäº¤é‡‘é¢ã€‚
    ç„¶åç¡®å®šæ„æˆå‰ n% æˆäº¤é‡‘é¢çš„è‚¡ç¥¨æ•°é‡ï¼Œå¹¶è®¡ç®—è¿™äº›è‚¡ç¥¨çš„å¹³å‡æ¶¨å¹…ã€‚

    å‚æ•°:
        n (float): è¦è®¡ç®—çš„è‚¡ç¥¨ç™¾åˆ†æ¯”ã€‚

    è¿”å›:
        float: å‰ n% æˆäº¤é‡‘é¢çš„è‚¡ç¥¨çš„å¹³å‡æ¶¨å¹…ã€‚å¦‚æœæ•°æ®ä¸ºç©ºï¼Œåˆ™è¿”å›0ã€‚
    """
    # è·å– A è‚¡å®æ—¶è¡Œæƒ…æ•°æ®
    # åºå·	ä»£ç 	åç§°	æœ€æ–°ä»·	æ¶¨è·Œå¹…	æ¶¨è·Œé¢	æˆäº¤é‡	æˆäº¤é¢	æŒ¯å¹…	æœ€é«˜	...	é‡æ¯”	æ¢æ‰‹ç‡	å¸‚ç›ˆç‡-åŠ¨æ€	å¸‚å‡€ç‡	æ€»å¸‚å€¼	æµé€šå¸‚å€¼	æ¶¨é€Ÿ	5åˆ†é’Ÿæ¶¨è·Œ	60æ—¥æ¶¨è·Œå¹…	å¹´åˆè‡³ä»Šæ¶¨è·Œå¹…
    df = ak.stock_zh_a_spot_em()
    if df.empty:
        logger.info("å®æ—¶è¡Œæƒ…æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—å¹³å‡æ¶¨å¹…")
        return 0

    # æŒ‰æˆäº¤é‡‘é¢é™åºæ’åº
    df_sorted = df.sort_values("æˆäº¤é¢", ascending=False)

    # è®¡ç®—å‰ n% çš„è‚¡ç¥¨æ•°é‡
    num_stocks = len(df)
    top_n_percent = int(num_stocks * (n / 100))

    # è®¡ç®—å‰ n% è‚¡ç¥¨çš„åŠ æƒå¹³å‡æ¶¨å¹…
    top_n_weighted_avg_price_change = (
        df_sorted["æ¶¨è·Œå¹…"].head(top_n_percent)
        * df_sorted["æ€»å¸‚å€¼"].head(top_n_percent)
    ).sum() / df_sorted["æ€»å¸‚å€¼"].head(top_n_percent).sum()

    # è®¡ç®—å‰ n% è‚¡ç¥¨çš„ç®—æ•°å¹³å‡æ¶¨å¹…ï¼Œå»é™¤æ¶¨å¹…è¶…è¿‡31%çš„è‚¡ç¥¨
    top_n_avg_price_change = (
        df_sorted[df_sorted["æ¶¨è·Œå¹…"] < 31]["æ¶¨è·Œå¹…"].head(top_n_percent).mean()
    )

    logger.info(f"å‰ {n}% æˆäº¤é‡‘é¢çš„è‚¡ç¥¨çš„å¹³å‡æ¶¨å¹…ä¸º: {top_n_avg_price_change:.2f}%")

    return top_n_weighted_avg_price_change, top_n_avg_price_change


@st.cache_data(ttl=180)
def top_n_stock_amount_percent(n):
    """
    è®¡ç®—å‰ n% çš„è‚¡ç¥¨å¯¹æ€»æˆäº¤é‡çš„è´¡çŒ®ç™¾åˆ†æ¯”ã€‚

    è¯¥å‡½æ•°è·å–Aè‚¡çš„å®æ—¶äº¤æ˜“æ•°æ®ï¼Œå°†è‚¡ç¥¨æŒ‰æˆäº¤é‡é™åºæ’åºï¼Œå¹¶è®¡ç®—æ€»æˆäº¤é‡ã€‚
    ç„¶åç¡®å®šæ„æˆå‰ n% æˆäº¤é‡çš„è‚¡ç¥¨æ•°é‡ï¼Œå¹¶è®¡ç®—è¿™äº›è‚¡ç¥¨çš„æ€»æˆäº¤é‡ã€‚
    æœ€åï¼Œè®¡ç®—å‰ n% çš„è‚¡ç¥¨å¯¹æ€»æˆäº¤é‡çš„è´¡çŒ®ç™¾åˆ†æ¯”ã€‚

    å‚æ•°:
        n (float): è¦è®¡ç®—çš„è‚¡ç¥¨ç™¾åˆ†æ¯”ã€‚

    è¿”å›:
        float: å‰ n% çš„è‚¡ç¥¨å¯¹æ€»æˆäº¤é‡çš„è´¡çŒ®ç™¾åˆ†æ¯”ã€‚å¦‚æœæ€»æˆäº¤é‡ä¸ºé›¶ï¼Œåˆ™è¿”å›0ã€‚
    """

    # è·å– A è‚¡å®æ—¶è¡Œæƒ…æ•°æ®
    df = ak.stock_zh_a_spot_em()
    # æŒ‰æˆäº¤é‡é™åºæ’åº
    df_sorted = df.sort_values("æˆäº¤é‡", ascending=False)

    # è®¡ç®—å‰ n% çš„è‚¡ç¥¨æ•°é‡
    num_stocks = len(df)
    top_n_percent = int(num_stocks * (n / 100))

    # è®¡ç®—æ€»æˆäº¤é‡
    total_amount = df["æˆäº¤é‡"].sum()

    if total_amount == 0:
        logger.info("æ€»æˆäº¤é‡ä¸º0, å¯èƒ½æ˜¯ç›˜å‰ï¼Œæ— æ³•è®¡ç®—æ‹¥æŒ¤åº¦")
        return 0

    # è®¡ç®—å‰ n% è‚¡ç¥¨çš„æˆäº¤é‡æ€»å’Œ
    top_n_percent_amount = df_sorted["æˆäº¤é‡"].head(top_n_percent).sum()

    # è®¡ç®—æ‹¥æŒ¤åº¦
    crowdedness = top_n_percent_amount / total_amount
    logger.info(f"å‰ {n}% æˆäº¤é‡çš„è‚¡ç¥¨å æ€»æˆäº¤é‡çš„ {crowdedness*100:.2f}%")

    return crowdedness


# ç®€å•çš„é¢„æµ‹æ¨¡å‹
def predict_amount(current_amount, current_time):
    if not during_market_time(current_time):
        return current_amount  # å¦‚æœå½“å‰æ—¶é—´è¶…è¿‡15:00ï¼Œè¿”å›å½“å‰æˆäº¤é¢ä½œä¸ºé¢„æµ‹å€¼

    elapsed_minutes = minutes_since_market_open(current_time)

    # ä½¿ç”¨ get_estimate_amount è·å–é¢„æµ‹çš„æˆäº¤é¢
    predicted_amount = get_estimate_amount(elapsed_minutes, current_amount)

    return predicted_amount


def streamlit_options(etf):
    st.title(f"{etf}æœŸæƒåˆ†æ")

    # 300ETFæœŸæƒåˆ†æ
    filtered_df = find_primary_options(etf)
    atm_options, avg_amountatility, underlying_price = analyze_atm_options(filtered_df)

    st.write(f"æ ‡çš„ETFä»·æ ¼: {underlying_price:.3f}")
    st.write(f"å¹³å‡ATMéšå«æ³¢åŠ¨ç‡: :red[{avg_amountatility:.2f}%]")
    st.write("\nATMæœŸæƒ:")
    # æŒ‰ç…§æœŸæƒç±»å‹ï¼ˆè´­å’Œæ²½ï¼‰å’Œè¡Œæƒä»·æ’åº
    atm_options_sorted = atm_options.sort_values(by=["æœŸæƒåç§°", "è¡Œæƒä»·"])

    st.dataframe(
        atm_options_sorted[["æœŸæƒåç§°", "æœ€æ–°ä»·", "éšå«æ³¢åŠ¨ç‡", "è¡Œæƒä»·"]].reset_index(
            drop=True
        ),
        use_container_width=True,
    )

    # é¢å¤–åˆ†æ
    call_options = atm_options[atm_options["æœŸæƒåç§°"].str.contains("è´­")]
    put_options = atm_options[atm_options["æœŸæƒåç§°"].str.contains("æ²½")]

    st.write(f"\nATMè´­æœŸæƒå¹³å‡éšå«æ³¢åŠ¨ç‡: {call_options['éšå«æ³¢åŠ¨ç‡'].mean():.2f}%")
    st.write(f"ATMæ²½æœŸæƒå¹³å‡éšå«æ³¢åŠ¨ç‡: {put_options['éšå«æ³¢åŠ¨ç‡'].mean():.2f}%")

    # æ‰¾åˆ°æœ€æ¥è¿‘ATMçš„æœŸæƒ
    closest_option = atm_options.loc[
        (atm_options["è¡Œæƒä»·"] - underlying_price).abs().idxmin()
    ]
    st.write(f"\næœ€æ¥è¿‘ATMçš„æœŸæƒ: {closest_option['æœŸæƒåç§°']}")
    st.write(f"è¡Œæƒä»·: {closest_option['è¡Œæƒä»·']:.3f}")
    st.write(f"éšå«æ³¢åŠ¨ç‡: {closest_option['éšå«æ³¢åŠ¨ç‡']:.2f}%")


@st.cache_data(ttl=180)
def get_top_n_popular_stocks(n):
    """
    è·å–æˆäº¤é¢å‰ N çš„è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯å’Œç»Ÿè®¡æ•°æ®ã€‚

    å‚æ•°:
        n (int): è·å–å‰ N åªè‚¡ç¥¨çš„ä¿¡æ¯

    è¿”å›:
        df: åŒ…å«å‰ N åªè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯å’Œç»Ÿè®¡æ•°æ®çš„ DataFrameã€‚
    """
    try:
        # è·å– A è‚¡å®æ—¶è¡Œæƒ…æ•°æ®
        df = ak.stock_zh_a_spot_em()
        if df.empty:
            logger.info("å®æ—¶è¡Œæƒ…æ•°æ®ä¸ºç©º")
            return None

        # æŒ‰æˆäº¤é¢é™åºæ’åº
        df_sorted = df.sort_values("æˆäº¤é¢", ascending=False)

        # è·å–å‰ N åªè‚¡ç¥¨
        top_n_stocks = df_sorted.head(n).copy()

        # é€‰æ‹©éœ€è¦çš„åˆ—å¹¶é‡å‘½å
        result_df = top_n_stocks[
            ["ä»£ç ", "åç§°", "æœ€æ–°ä»·", "æ¶¨è·Œå¹…", "æˆäº¤é¢", "æ€»å¸‚å€¼", "æ¢æ‰‹ç‡"]
        ].copy()

        # æ ¼å¼åŒ–æ•°å€¼
        result_df["æ¶¨è·Œå¹…"] = result_df["æ¶¨è·Œå¹…"].apply(lambda x: f"{x:.2f}%")
        result_df["æ¢æ‰‹ç‡"] = result_df["æ¢æ‰‹ç‡"].apply(lambda x: f"{x:.2f}%")
        result_df["æˆäº¤é¢"] = (result_df["æˆäº¤é¢"] / 1e8).apply(lambda x: f"{int(x)}äº¿")
        result_df["æ€»å¸‚å€¼"] = (result_df["æ€»å¸‚å€¼"] / 1e8).apply(lambda x: f"{int(x)}äº¿")
        result_df["æœ€æ–°ä»·"] = result_df["æœ€æ–°ä»·"].apply(lambda x: f"{x:.2f}")

        # è®¾ç½®ç´¢å¼•ä¸ºåç§°ï¼Œä½†ä¸æ˜¾ç¤ºç´¢å¼•å
        result_df.set_index("åç§°", inplace=True)

        return result_df

    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        return None


@st.cache_data(ttl=180)
def calculate_top_n_stocks_avg_market_value(n):
    """
    è®¡ç®—æˆäº¤é¢å‰Nçš„è‚¡ç¥¨çš„å¹³å‡å¸‚å€¼ã€‚

    å‚æ•°:
        n (int): è¦è®¡ç®—çš„è‚¡ç¥¨æ•°é‡

    è¿”å›:
        tuple: (avg_market_value, total_market_value, stocks_count)
        - avg_market_value: å¹³å‡å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰
        - total_market_value: æ€»å¸‚å€¼ï¼ˆäº¿å…ƒï¼‰
        - stocks_count: å®é™…ç»Ÿè®¡çš„è‚¡ç¥¨æ•°é‡
    """
    try:
        logger.info(f"å¼€å§‹è®¡ç®—å‰{n}åªè‚¡ç¥¨çš„å¹³å‡å¸‚å€¼")
        df = ak.stock_zh_a_spot_em()

        if df.empty:
            logger.warning("è·å–åˆ°çš„è‚¡ç¥¨æ•°æ®ä¸ºç©º")
            return 0, 0, 0

        # æŒ‰æˆäº¤é¢é™åºæ’åºå¹¶è·å–å‰Nåª
        df_sorted = df.sort_values("æˆäº¤é¢", ascending=False).head(n)

        # è®¡ç®—å¸‚å€¼ï¼ˆè½¬æ¢ä¸ºäº¿å…ƒï¼‰
        total_market_value = df_sorted["æ€»å¸‚å€¼"].sum() / 1e8
        avg_market_value = df_sorted["æ€»å¸‚å€¼"].mean() / 1e8
        stocks_count = len(df_sorted)

        logger.info(f"å‰{stocks_count}åªè‚¡ç¥¨å¹³å‡å¸‚å€¼: {avg_market_value:.2f}äº¿")
        logger.info(f"å‰{stocks_count}åªè‚¡ç¥¨æ€»å¸‚å€¼: {total_market_value:.2f}äº¿")

        return avg_market_value, total_market_value, stocks_count
    except Exception as e:
        logger.error(f"è®¡ç®—å¹³å‡å¸‚å€¼æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return 0, 0, 0


def get_market_heat():
    logger.info("ç¨‹åºå¯åŠ¨")
    # Streamlit é¡µé¢è®¾ç½®

    # è·å–å½“å‰æˆäº¤é¢
    logger.info("å¼€å§‹è·å–å½“å‰æˆäº¤é¢")
    sh_amount, sz_amount = get_a_amount()

    # å½“å‰æ—¶é—´
    current_time = datetime.now()

    # é¢„æµ‹æˆäº¤é¢
    sh_pred = predict_amount(sh_amount, current_time)
    sz_pred = predict_amount(sz_amount, current_time)

    # è®¡ç®—æ€»æˆäº¤é¢å’Œé¢„æµ‹æ€»æˆäº¤é¢
    total_amount = sh_amount + sz_amount
    total_pred = sh_pred + sz_pred

    # åˆ›ä¸šæ¿æˆäº¤å æ¯”ï¼ˆæ•£æˆ·è·Ÿé£æŒ‡æ ‡ï¼‰
    cyb_amount = get_index_amount("399006")

    # è®¡ç®—åˆ›ä¸šæ¿æˆäº¤å æ€»æˆäº¤æ¯”ä¾‹
    cyb_ratio = cyb_amount / total_amount * 100

    # æ²ªæ·± 300 æˆäº¤å æ¯”
    hs300_amount = get_index_amount("000300")
    hs300_ratio = hs300_amount / total_amount * 100

    # ä¸­è¯ 1000 æˆäº¤å æ¯”
    zz1000_amount = get_index_amount("399852")
    zz1000_ratio = zz1000_amount / total_amount * 100

    # ä¸­è¯ 2000 æˆäº¤å æ¯”
    zz2000_amount = get_index_amount("932000")
    zz2000_ratio = zz2000_amount / total_amount * 100

    # è·å–5æ—¥å‡å€¼
    avg_5_day = get_n_day_avg_amount(5)

    # æ‹¥æŒ¤åº¦ï¼Œç®—æ³•å‚è§https://legulegu.com/stockdata/ashares-congestion
    crowdedness = top_n_stock_amount_percent(5) * 100

    # ä¸­é—´è‚¡ç¥¨æ¶¨å¹…
    middle_price_change_value = middle_price_change()

    # top5 æˆäº¤é¢è‚¡ç¥¨å¹³å‡æ¶¨å¹…å’ŒåŠ æƒå¹³å‡æ¶¨å¹…
    top5_weighted_avg_price_change, top5_avg_price_change = (
        top_n_stock_avg_price_change(5)
    )
    # è‚¡ç¥¨æ¶¨è·Œæ¯”
    up_down_ratio = stock_up_down_ratio()

    # æ¶¨åœæ•°é‡
    limit_up_count = count_limit_up_stocks()
    # è·Œåœæ•°é‡
    limit_down_count = count_limit_down_stocks()

    # è®¡ç®—å‰10åªè‚¡ç¥¨çš„å¹³å‡å¸‚å€¼
    avg_market_value, total_market_value, stocks_count = (
        calculate_top_n_stocks_avg_market_value(10)
    )
    # æ˜¾ç¤ºå‰10åªæ´»è·ƒè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯
    top_stocks = get_top_n_popular_stocks(10)

    # åˆ›å»ºæ•°æ®å­—å…¸
    data = {
        "æŒ‡æ ‡": [
            "ä¸Šè¯æˆäº¤é¢",
            "æ·±è¯æˆäº¤é¢",
            "åˆ›ä¸šæ¿æˆäº¤é¢",
            "å½“å‰æ€»æˆäº¤é¢",
            "åˆ›ä¸šæ¿æˆäº¤å æ€»æˆäº¤æ¯”ä¾‹",
            "ä¸­è¯ 1000 æˆäº¤å æ€»æˆäº¤æ¯”ä¾‹",
            "ä¸­è¯ 2000 æˆäº¤å æ€»æˆäº¤æ¯”ä¾‹",
            "æ²ªæ·± 300 æˆäº¤å æ€»æˆäº¤æ¯”ä¾‹",
            "é¢„è®¡ä»Šæ—¥æ€»æˆäº¤é¢",
            "5æ—¥å‡å€¼",
            "äº¤æ˜“æ‹¥æŒ¤åº¦",
            "ä¸­ä½æ•°è‚¡ç¥¨æ¶¨å¹…",
            "å‰ 5% æˆäº¤åŠ æƒæ¶¨å¹…",
            "å‰ 5% æˆäº¤ç®—æ•°æ¶¨å¹…",
            "è‚¡ç¥¨ä¸Šæ¶¨ç™¾åˆ†æ¯”",
            "æ¶¨åœæ¿è‚¡ç¥¨æ•°é‡",
            "è·Œåœæ¿è‚¡ç¥¨æ•°é‡",
            f"å‰{stocks_count}å¤§æˆäº¤é¢è‚¡ç¥¨å¹³å‡å¸‚å€¼",
            f"å‰{stocks_count}å¤§æˆäº¤é¢è‚¡ç¥¨æ´»è·ƒåº¦",
        ],
        "æ•°å€¼": [
            f"{sh_amount/1e8:.0f} äº¿",
            f"{sz_amount/1e8:.0f} äº¿",
            f"{cyb_amount/1e8:.0f} äº¿",
            f"{total_amount/1e8:.0f} äº¿",
            f"{cyb_ratio:.2f}%",
            f"{zz1000_ratio:.2f}%",
            f"{zz2000_ratio:.2f}%",
            f"{hs300_ratio:.2f}%",
            (
                color_text(f"{total_pred/1e8:.0f} äº¿", lambda: total_pred > 10000)
                if is_trade_date(datetime.now(pytz.timezone("Asia/Shanghai")).date())
                else "N/A"
            ),
            f"{avg_5_day/1e8:.0f} äº¿",
            color_text(f"{crowdedness:.2f}", lambda: crowdedness < 50),
            color_text(
                f"{middle_price_change_value:.2f}%",
                lambda: middle_price_change_value > 0,
            ),
            color_text(
                f"{top5_weighted_avg_price_change:.2f}%",
                lambda: top5_weighted_avg_price_change > 0,
            ),
            color_text(
                f"{top5_avg_price_change :.2f}%", lambda: top5_avg_price_change > 0
            ),
            color_text(f"{up_down_ratio:.2f}%", lambda: up_down_ratio > 50),
            limit_up_count,
            limit_down_count,
            f"{int(avg_market_value)}äº¿",
            top_stocks,
        ],
    }

    return data


placeholder = st.empty()  # åˆ›å»ºä¸€ä¸ªç©ºç™½åŒºåŸŸ


def color_negative_red(val):
    try:
        val = float(val.rstrip("%"))
    except ValueError:
        return ""
    color = "red" if val > 0 else "green"
    return f"color: {color}"


def streamlit_market_heat():
    data = get_market_heat()

    # åˆ›å»ºä¸¤åˆ—
    col1, col2 = st.columns([2, 2])

    with col1:
        # å·¦æ æ˜¾ç¤ºæˆäº¤é¢å’Œæƒ…ç»ªæŒ‡æ ‡
        st.header("æˆäº¤é¢")
        for item, value in zip(data["æŒ‡æ ‡"][0:10], data["æ•°å€¼"][0:10]):
            st.write(f"{item}: {value}")

        st.header("æƒ…ç»ªæŒ‡æ ‡")
        for item, value in zip(data["æŒ‡æ ‡"][10:17], data["æ•°å€¼"][10:17]):
            st.write(f"{item}: {value}")

        if st.button("æ¸…é™¤ç¼“å­˜"):
            st.cache_data.clear()
            ak.clear_cache()
            st.success("ç¼“å­˜å·²æ¸…é™¤")

    with col2:
        # å³æ æ˜¾ç¤ºé¾™å¤´è‚¡åˆ†æ
        st.header("é¾™å¤´è‚¡åˆ†æ")
        st.write(f"{data['æŒ‡æ ‡'][17]}: {data['æ•°å€¼'][17]}")
        if data["æ•°å€¼"][18] is not None:
            styled_df = data["æ•°å€¼"][18].style.map(
                color_negative_red, subset=["æ¶¨è·Œå¹…"]
            )
            st.dataframe(
                styled_df,
                use_container_width=True,
                hide_index=False,  # æ˜¾ç¤ºè‚¡ç¥¨åç§°ä½œä¸ºç´¢å¼•
            )


def streamlit_spread_chart():
    st.title("æŒ‡æ•°40æ—¥æ”¶ç›Šå·®åˆ†æ")

    # åˆ›å»ºå›¾è¡¨å¹¶è·å–å½“å‰æ”¶ç›Šå·®
    fig, hs300_zz1000_spread, zz1000_dividend_spread = create_spread_chart()

    # æ˜¾ç¤ºå›¾è¡¨
    st.plotly_chart(fig, use_container_width=True)

    # æ˜¾ç¤ºå½“å‰æ”¶ç›Šå·®
    col1, col2 = st.columns(2)
    with col1:
        st.write(f"æ²ªæ·±300-ä¸­è¯1000æ”¶ç›Šå·®: {hs300_zz1000_spread:.2f}%")
    with col2:
        st.write(f"ä¸­è¯1000-çº¢åˆ©æŒ‡æ•°æ”¶ç›Šå·®: {zz1000_dividend_spread:.2f}%")


def streamlit_app():
    # Run the autorefresh about every 2000 milliseconds (2 seconds)
    st_autorefresh(interval=60000, key="data_refresh")

    streamlit_market_heat()

    streamlit_spread_chart()

    # æ•°æ®æ›´æ–°æ—¶é—´
    current_time = datetime.now()
    updated_at = current_time.astimezone(pytz.timezone("Asia/Shanghai")).strftime(
        "%Y-%m-%d %H:%M:%S"
    )
    status = "ï¼ˆéäº¤æ˜“æ—¶é—´ï¼‰" if not during_market_time(current_time) else ""
    st.write("æ•°æ®æ›´æ–°æ—¶é—´:", updated_at, status)


if __name__ == "__main__":
    streamlit_app()
